---
- hosts: haipproxy
  remote_user: zzw
  vars:
    splash_url: http://127.0.0.1:8050
    redis_host: 127.0.0.1
    redis_port: 6379
    redis_password: ''
  tasks:
    - name: create haipproxy directory
      file:
        path: /home/zzw/haipproxy
        state: directory
#    - name: download haipproxy source code
#      get_url: url=https://github.com/SpiderClub/haipproxy/archive/v0.1.tar.gz dest=/home/zzw/software/haipproxy-v0.1.tar.gz
    - name: get haipproxy source code
      unarchive:
        src: https://github.com/SpiderClub/haipproxy/archive/v0.1.tar.gz
        dest: /home/zzw/haipproxy
        remote_src: yes
    - include: redis.yml
#    - name: install scrapy-splash
#      pip:
#        name: scrapy-splash
#      become: True
#    - name: start scrapy-splash
#      raw: python3 -m splash.server --port=8050
#    - name: haipproxy setting
#      template:
#        src: haipproxy/settings.py
#        dest: /home/zzw/haipproxy/haipproxy-0.1/config/settings.py
    - name: remove docker
      yum:
        name: docker-ce
        state: absent
      become: True
    - name: install docker
      yum:
        name: docker-ce.x86_64
        state: present
        update_cache: yes
      become: True
    - name: start docker service
      service:
        name: docker
        state: started
      become: True
    - name: pull docker splash image
      shell: docker pull scrapinghub/splash
      become: True
    - name: start splash container
      shell: docker run -it -p 8050:8050 scrapinghub/splash
      become: True


